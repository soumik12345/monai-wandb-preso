<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>reveal.js</title>

		<link rel="stylesheet" href="dist/reset.css">
		<link rel="stylesheet" href="dist/reveal.css">
		<link rel="stylesheet" href="dist/theme/night.css">

		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="plugin/highlight/monokai.css">
		<style>
			.circular_image {
				width: 70%;
				height: 70%;
				border-radius: 50%;
				overflow: hidden;
				display:inline-block;
				vertical-align:middle;
			  }
			  .circular_image img{
				width:100%;
			  }

			  #left {
				left:-8.33%;
				text-align: left;
				float: left;
				width:50%;
				z-index:-10;
			  }
			  
			  #right {
				left:31.25%;
				top: 75px;
				float: right;
				text-align: right;
				z-index:-10;
				width:50%;
			  }
		</style>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<!-- Slide 1 -->
				<section data-markdown>
					<textarea data-template>
					  ## Brain Tumor Segmentation using MONAI and WandB

					  Presented by [Soumik Rakshit](https://geekyrakshit.dev/)
					</textarea>
				</section>
				<!-- Slide 2 -->
				<section data-markdown>
					<textarea data-template>
						<div id="left">
							<p>
								Follow along at <br>
								<p style="padding-top: 5%;"><a href="bit.ly/monai-wandb-preso">geekyrakshit.dev/monai-wandb-preso</a></p>
							</p>
						</div>
						<div id="right">
							<img src="./examples/assets/qr1.png" alt="">
						</div>
					</textarea>
				</section>
				<!-- Slide 3 -->
				<section data-markdown>
					<textarea data-template>
						<div id="left">
							<img class="circular_image" src="https://geekyrakshit.dev/assets/soumik_rakshit.png" alt="">
						</div>
						<div id="right">
							<p style="text-align: left; font-size: 80%; padding-bottom: 5%;">$>whoami</p>
							<p style="text-align: left; font-size: 50%; line-height: 175%;">
								üëã Building tools for ML <a href="https://wandb.ai/site">@WandB</a>.<br>
								üëã Google Developer Expert in ML (JAX).<br>
								üëã Former ML Research @IBM and @Ignitarium.<br>
								üëã I build MLOps pipelines for open-source repositories (Keras, ü§ó Diffusers, MonAI, etc.)<br>
								üëã I am actively working on <a href="https://github.com/soumik12345/wandb-addons"></a>WandB-Addons</a>.<br>
								üëã Playing üéª between work; MineCraft and Elden Ring after work.<br>
								üëã More about myself at <a href="https://geekyrakshit.dev/">geekyrakshit.dev</a>
							</p>
						</div>
					</textarea>
				</section>
				<!-- Slide 4 -->
				<section>
					<section>
						Machine Learning is revolutionizing many fields of medicine
					</section>
					<section>
						accurate disease diagnosis
					</section>
					<section>
						early prediction of adverse events
					</section>
					<section>
						automatic discovery of antibiotics
					</section>
					<section>
						LLMs deployed on clinical trial reporting
					</section>
					<section>
						<p style="font-size: 150%; padding-bottom: 10%;"><a href="#/3/5"><strong>
							Automatic Analysis of Medical Images
						</strong></a></p>
					</section>
				</section>
				<!-- Slide 5 -->
				<section>
					<p>Today we'll discuss</p>
					<p style="font-size: 150%; padding-top: 10%;"><a href="#/4"><strong>
						Segmentation of Brain Tumors from MRI Scans
					</strong></a></p>
				</section>
				<!-- Slide 6 -->
				<section data-markdown>
					<textarea data-template>
						<div id="left">
							<img src="./examples/assets/image4.gif" alt="" style="height: 200%; width: 200%;">
						</div>
						<div id="right">
							<p style="text-align: left; font-size: 80%; padding-bottom: 5%;">Why Semantic Segmentaion?</p>
							<p style="text-align: left; font-size: 40%; line-height: 175%;">
								‚õëÔ∏è <a href="#/5">Semantic segmentation</a> refers to the process of transforming raw medical images into clinically relevant, spatially structured information, such as outlining tumor boundaries.<br>
							</p>
							<p style="text-align: left; font-size: 40%; line-height: 175%;">
								‚õëÔ∏è Semantic segmentation is an essential prerequisite for a number of clinical applications, such as <a href="#/5">radiotherapy planning</a> and <a href="#/5">treatment response monitoring</a>.<br>
							</p>
							<p style="text-align: left; font-size: 40%; line-height: 175%;">
								‚õëÔ∏è Semantic segmentation is, right now, the <a href="#/5">most widely investigated medical image processing task</a>, with <a href="#/5">~70%</a> of all biomedical image analysis challenges dedicated to it, according to the paper <a href="https://www.nature.com/articles/s41467-022-30695-9#Sec1">The Medical Segmentation Decathlon</a>.<br>
							</p>
						</div>
					</textarea>
				</section>
				<!-- Slide 7 -->
				<section>
					<section>üõ†Ô∏è Tools of the Trade</section>
					<section><img src="https://raw.githubusercontent.com/Project-MONAI/MONAI/dev/docs/images/MONAI-logo-color.png" alt=""></section>
					<section data-markdown>
						<textarea data-template>
							<p class="fragment fade-in-then-out">a set of open-source, freely available collaborative frameworks</p>
							<p class="fragment fade-in-then-out">built for accelerating research and clinical collaboration in medical imaging</p>
							<p class="fragment fade-in-then-out">accelerate the pace of innovation and clinical translation using a robust software framework</p>
							<p class="fragment fade-in-then-out">covers nearly every level of medical imaging, deep learning research, and deployment</p>
						</textarea>
					</section>
					<section data-background-color="rgb(255, 255, 255)">
						<img src="https://raw.githubusercontent.com/wandb/assets/main/wandb-logo-yellow-dots-black-wb.svg" alt="">
					</section>
					<section data-markdown>
						<textarea data-template>
							<p class="fragment fade-in-then-out">the developer-first MLOps platform</p>
							<p class="fragment fade-in-then-out">makes it easy to track your experiments, manage, and version your data</p>
							<p class="fragment fade-in-then-out">collaborate with your team so you can focus on building the best models</p>
							<p class="fragment fade-in-then-out">effortless model management and hyperparameter optimization</p>
						</textarea>
					</section>
				</section>
				<!-- Slide 8 -->
				<section>
					<section>
						<p style="font-size: 150%;"><a href="https://medicaldecathlon.com/">
							The Medical Decathlon Dataset
						</a></p>
					</section>
					<section>
						In this report, we will be focusing on training a deep neural network on the dataset for the
						<a href="#/7/1">Brain Tumor Segmentation </a> task from the
						<a href="https://medicaldecathlon.com/">Medical Segmentation Decathlon</a>.
					</section>
					<section>
						<p class="fragment fade-in-then-out">The goal of this challenge is to produce segmentation labels of the different <strong>glioma</strong> sub regions</p>
						<p class="fragment fade-in">Tumor core</p>
						<p class="fragment fade-in">Whole tumor</p>
						<p class="fragment fade-in">Enhancing tumor</p>
					</section>
				</section>
				<!-- Slide 9 -->
				<section>
					<p style="font-size: 150%;">
						üíø Loading and Exploring the Data
					</p>
				</section>
				<!-- Slide 10 -->
				<section>
					<section>Step 1: Define the Transforms</section>
					<section data-markdown><textarea data-template>
						We define some transforms to be applied to our data after loading for the sake of pre-processing and batching.
					</textarea></section>
					<section data-markdown><textarea data-template>
						We can do this easily using the [`monai.transforms`](https://docs.monai.io/en/stable/transforms.html) API
						that provides a large collection of PyTorch-based transforms specific to medical imaging.
					</textarea></section>
					<section>
						<p data-id="code-title">Defining the Transforms</p>
						<pre data-id="code-animation"><code class="hljs python" data-trim data-line-numbers="|1,6-8|14-15|21-22|28-34|40-42|48-53|59-62|68-73|79-80"><script type="text/template">
							from monai.transforms import *

							train_transform = Compose(
								[
									
									# Load tensors from the specified files.
									# Load 4 Nifti images and stack them together.
									LoadImaged(keys=["image", "label"]),

									
									
									
									
									# Ensure channel-first ordering for images and labels.
									EnsureChannelFirstd(keys="image"),
									
									
									
									
									
									# Convert the labels to BRATS classes.
									ConvertToMultiChannelBasedOnBratsClassesd(keys="label"),
									
									
									
									
									
									# Resample the input image into the specified
									# pixel dimension.
									Spacingd(
										keys=["image", "label"],
										pixdim=(1.0, 1.0, 1.0),
										mode=("bilinear", "nearest"),
									),





									# Change the orientation of the input image into the specified
									# based on spatial axcodes.
									Orientationd(keys=["image", "label"], axcodes="RAS"),
									
									
									
									
									
									# Crop image with random size or specifically sized
									# region-of-interest.
									RandSpatialCropd(
										keys=["image", "label"],
										roi_size=[224, 224, 144], random_size=False
									),





									# Random flip images and labels across all the apatial axes
									RandFlipd(keys=["image", "label"], prob=0.5, spatial_axis=0),
									RandFlipd(keys=["image", "label"], prob=0.5, spatial_axis=1),
									RandFlipd(keys=["image", "label"], prob=0.5, spatial_axis=2),
									
									
									
									
									
									# Normalize and randomly scale inputs based on intensity.
									NormalizeIntensityd(
											keys="image", nonzero=True, channel_wise=True
									),
									RandScaleIntensityd(keys="image", factors=0.1, prob=1.0),
									RandShiftIntensityd(keys="image", offsets=0.1, prob=1.0),
									
									
									
									
									
									# Ensure the input data to be a PyTorch Tensor or numpy array.
									EnsureTyped(keys=["image", "label"]),
								]
							)
						</script></code></pre>
					</section>
				</section>
				<!-- Slide 11 -->
				<section>
					<p style="font-size: 150%;">üêù <a href="#/10">Quiz Time...</a><br></p>
					<p class="fragment fade-in">
						What would be the difference between the transforms applied to the
						training data and the validation data?
					</p>
				</section>
				<!-- Slide 12 -->
				<section>
					<section>Step 2: Create the Dataloader</section>
					<section data-markdown><textarea data-template>
						We use [`monai.apps.DecathlonDataset`](https://docs.monai.io/en/stable/apps.html#monai.apps.DecathlonDataset)
						to automatically download the data of Medical Segmentation Decathlon challenge and generate items
						for training, validation or test.
					</textarea></section>
					<section>
						<p data-id="code-title">Defining the Transforms</p>
						<pre data-id="code-animation"><code class="hljs python" data-trim data-line-numbers="|1,4-9|2,11-14|"><script type="text/template">
							from monai.apps import DecathlonDataset
							from monai.data import DataLoader

							train_ds = DecathlonDataset(
								root_dir=artifact_dir, task="Task01_BrainTumour",
								transform=train_transform, section="training",
								download=True, cache_rate=0.0,
								num_workers=config.num_workers,
							)

							train_loader = DataLoader(
								train_ds, batch_size=config.train_batch_size,
								shuffle=True, num_workers=config.num_workers
							)
						</script></code></pre>
					</section>
				</section>
			</div>
		</div>

		<script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ]
			});
		</script>
	</body>
</html>
